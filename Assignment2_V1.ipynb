{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random, csv\n",
    "import numpy as np\n",
    "#import igraph\n",
    "from sklearn import svm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "from sklearn import preprocessing\n",
    "import nltk\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading test and train data, and node info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#nltk.download('punkt') # for tokenization\n",
    "#nltk.download('stopwords')\n",
    "stpwds = set(nltk.corpus.stopwords.words(\"english\"))\n",
    "stemmer = nltk.stem.PorterStemmer()\n",
    "\n",
    "with open(\"testing_set.txt\", \"r\") as f:\n",
    "    reader = csv.reader(f)\n",
    "    testing_set  = list(reader)\n",
    "\n",
    "testing_set = [element[0].split(\" \") for element in testing_set]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"training_set.txt\", \"r\") as f:\n",
    "    reader = csv.reader(f)\n",
    "    training_set  = list(reader)\n",
    "\n",
    "training_set = [element[0].split(\" \") for element in training_set]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"node_information.csv\", \"r\") as f:\n",
    "    reader = csv.reader(f)\n",
    "    node_info  = list(reader)\n",
    "\n",
    "IDs = [element[0] for element in node_info]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating graph (nodes and edges from training data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = [(element[0],element[1]) for element in training_set if element[2]==\"1\"]\n",
    "nodes = [element[0] for element in training_set] + [element[1] for element in training_set]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the actual directed graph\n",
    "G = nx.DiGraph()\n",
    "G.add_nodes_from(nodes)\n",
    "G.add_edges_from(edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# undirected version of the graph (used for jaccard similarity)\n",
    "G_undirected = nx.Graph()\n",
    "G_undirected.add_nodes_from(nodes)\n",
    "G_undirected.add_edges_from(edges)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NUM_EXAMPLES = 100000\n",
    "NUM_TRAIN = 70000\n",
    "NUM_VALIDATION = 30000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating features for the entire data to store in csv file\n",
    "##### since this is very slow, I am writing only 50000 examples for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 training examples processsed\n",
      "2001 training examples processsed\n",
      "4001 training examples processsed\n",
      "6001 training examples processsed\n",
      "8001 training examples processsed\n",
      "10001 training examples processsed\n",
      "12001 training examples processsed\n",
      "14001 training examples processsed\n",
      "16001 training examples processsed\n",
      "18001 training examples processsed\n",
      "20001 training examples processsed\n",
      "22001 training examples processsed\n",
      "24001 training examples processsed\n",
      "26001 training examples processsed\n",
      "28001 training examples processsed\n",
      "30001 training examples processsed\n",
      "32001 training examples processsed\n",
      "34001 training examples processsed\n",
      "36001 training examples processsed\n",
      "38001 training examples processsed\n",
      "40001 training examples processsed\n",
      "42001 training examples processsed\n",
      "44001 training examples processsed\n",
      "46001 training examples processsed\n",
      "48001 training examples processsed\n",
      "50001 training examples processsed\n",
      "52001 training examples processsed\n",
      "54001 training examples processsed\n",
      "56001 training examples processsed\n",
      "58001 training examples processsed\n",
      "60001 training examples processsed\n",
      "62001 training examples processsed\n",
      "64001 training examples processsed\n",
      "66001 training examples processsed\n",
      "68001 training examples processsed\n",
      "70001 training examples processsed\n",
      "72001 training examples processsed\n",
      "74001 training examples processsed\n",
      "76001 training examples processsed\n",
      "78001 training examples processsed\n",
      "80001 training examples processsed\n",
      "82001 training examples processsed\n",
      "84001 training examples processsed\n",
      "86001 training examples processsed\n",
      "88001 training examples processsed\n",
      "90001 training examples processsed\n",
      "92001 training examples processsed\n",
      "94001 training examples processsed\n",
      "96001 training examples processsed\n",
      "98001 training examples processsed\n"
     ]
    }
   ],
   "source": [
    "### creating features and store in a csv file\n",
    "\n",
    "# number of overlapping words in title\n",
    "overlap_title = []\n",
    "\n",
    "# temporal distance between the papers\n",
    "temp_diff = []\n",
    "\n",
    "# number of common authors\n",
    "comm_auth = []\n",
    "\n",
    "# jaccard similarity\n",
    "jaccard_sim = []\n",
    "\n",
    "counter = 0\n",
    "for i in xrange(len(training_set[:NUM_EXAMPLES])):\n",
    "    source = training_set[i][0]\n",
    "    target = training_set[i][1]\n",
    "    \n",
    "    source_info = [element for element in node_info if element[0]==source][0]\n",
    "    target_info = [element for element in node_info if element[0]==target][0]\n",
    "    \n",
    "\t# convert to lowercase and tokenize\n",
    "    source_title = source_info[2].lower().split(\" \")\n",
    "\t# remove stopwords\n",
    "    source_title = [token for token in source_title if token not in stpwds]\n",
    "    source_title = [stemmer.stem(token) for token in source_title]\n",
    "    \n",
    "    target_title = target_info[2].lower().split(\" \")\n",
    "    target_title = [token for token in target_title if token not in stpwds]\n",
    "    target_title = [stemmer.stem(token) for token in target_title]\n",
    "    \n",
    "    source_auth = source_info[3].split(\",\")\n",
    "    target_auth = target_info[3].split(\",\")\n",
    "    \n",
    "    overlap_title.append(len(set(source_title).intersection(set(target_title))))\n",
    "    temp_diff.append(int(source_info[1]) - int(target_info[1]))\n",
    "    comm_auth.append(len(set(source_auth).intersection(set(target_auth))))\n",
    "   \n",
    "    preds = nx.jaccard_coefficient(G_undirected, [(source, target)])\n",
    "    for _, _, p in preds:\n",
    "        jaccard_sim.append(p)\n",
    "    \n",
    "    counter += 1\n",
    "    if counter % 2000 == True:\n",
    "        print counter, \"training examples processsed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert list of lists into array\n",
    "# documents as rows, unique words as columns (i.e., example as rows, features as columns)\n",
    "training_features = np.array([overlap_title, temp_diff, comm_auth, jaccard_sim]).T\n",
    "\n",
    "# scale\n",
    "training_features = preprocessing.scale(training_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write features to .csv file\n",
    "X_train = np.array(training_set[:NUM_EXAMPLES]).T\n",
    "X_features = training_features.T\n",
    "features = zip(X_train[0], X_train[1], X_train[2], X_features[0], X_features[1], X_features[2], X_features[3])\n",
    "with open(\"features.csv\",\"wb\") as feat:\n",
    "    csv_out = csv.writer(feat)\n",
    "    csv_out.writerow(('source', 'target', 'label', 'overlap_title', 'diff', 'common_author', 'jaccard_sim'))\n",
    "    for row in features:\n",
    "        csv_out.writerow(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading features from features.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading features\n",
    "with open(\"features.csv\", \"r\") as f:\n",
    "    reader = csv.reader(f)\n",
    "    feats = list(reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100001,\n",
       " ['1.6372487962605144', '-0.32515275343668099', '-0.23481201628467319'])"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(feats), feats[1][3:6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating training_features and validation_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert labels into integers then into column array\n",
    "\n",
    "labels = [int(element[2]) for element in feats[1:NUM_TRAIN+1]]\n",
    "labels_array = np.array(labels)\n",
    "training_features = [element[3:7] for element in feats[1:NUM_TRAIN+1]]\n",
    "training_features = np.array(training_features, dtype=np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000, array([  1.63724880e+00,  -3.25152753e-01,  -2.34812016e-01,\n",
       "          1.31323942e-03]))"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_features), training_features[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert labels into integers then into column array\n",
    "labels_validation = [int(element[2]) for element in feats[NUM_TRAIN+1:]]\n",
    "#labels_validation = list(labels_validation)\n",
    "labels_array_validation = np.array(labels_validation)\n",
    "validation_features = [element[3:7] for element in feats[NUM_TRAIN+1:]]\n",
    "validation_features = np.array(validation_features, dtype=np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, array([ 0.53333424,  0.52539418, -0.23481202,  1.02823117]))"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(validation_features), validation_features[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing basic SVM and predict on validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialize basic SVM\n",
    "classifier = svm.LinearSVC()\n",
    "\n",
    "# train\n",
    "classifier.fit(training_features, labels_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_SVM = list(classifier.predict(validation_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating the metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network size:  27770\n",
      "Number of training samples:  70000\n",
      "Number of validation samples:  30000\n",
      "F1-score:  0.933435396932\n",
      "Accuracy:  0.930433333333\n"
     ]
    }
   ],
   "source": [
    "import sklearn \n",
    "f1score = sklearn.metrics.f1_score(labels_array_validation, predictions_SVM)\n",
    "acc = sklearn.metrics.accuracy_score(labels_array_validation, predictions_SVM)\n",
    "\n",
    "print 'Network size: ', len(G.nodes())\n",
    "print 'Number of training samples: ', NUM_TRAIN\n",
    "print 'Number of validation samples: ', NUM_VALIDATION\n",
    "print 'F1-score: ', f1score\n",
    "print 'Accuracy: ', acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating features for test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 testing examples processsed\n",
      "1001 testing examples processsed\n",
      "2001 testing examples processsed\n",
      "3001 testing examples processsed\n",
      "4001 testing examples processsed\n",
      "5001 testing examples processsed\n",
      "6001 testing examples processsed\n",
      "7001 testing examples processsed\n",
      "8001 testing examples processsed\n",
      "9001 testing examples processsed\n",
      "10001 testing examples processsed\n",
      "11001 testing examples processsed\n",
      "12001 testing examples processsed\n",
      "13001 testing examples processsed\n",
      "14001 testing examples processsed\n",
      "15001 testing examples processsed\n",
      "16001 testing examples processsed\n",
      "17001 testing examples processsed\n",
      "18001 testing examples processsed\n",
      "19001 testing examples processsed\n",
      "20001 testing examples processsed\n",
      "21001 testing examples processsed\n",
      "22001 testing examples processsed\n",
      "23001 testing examples processsed\n",
      "24001 testing examples processsed\n",
      "25001 testing examples processsed\n",
      "26001 testing examples processsed\n",
      "27001 testing examples processsed\n",
      "28001 testing examples processsed\n",
      "29001 testing examples processsed\n",
      "30001 testing examples processsed\n",
      "31001 testing examples processsed\n",
      "32001 testing examples processsed\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "# we need to compute the features for the testing set\n",
    "\n",
    "overlap_title_test = []\n",
    "temp_diff_test = []\n",
    "comm_auth_test = []\n",
    "jaccard_sim=[]\n",
    "\n",
    "counter = 0\n",
    "for i in xrange(len(testing_set)):\n",
    "    source = testing_set[i][0]\n",
    "    target = testing_set[i][1]\n",
    "    \n",
    "    index_source = IDs.index(source)\n",
    "    index_target = IDs.index(target)\n",
    "    \n",
    "    source_info = [element for element in node_info if element[0]==source][0]\n",
    "    target_info = [element for element in node_info if element[0]==target][0]\n",
    "    \n",
    "    source_title = source_info[2].lower().split(\" \")\n",
    "    source_title = [token for token in source_title if token not in stpwds]\n",
    "    source_title = [stemmer.stem(token) for token in source_title]\n",
    "    \n",
    "    target_title = target_info[2].lower().split(\" \")\n",
    "    target_title = [token for token in target_title if token not in stpwds]\n",
    "    target_title = [stemmer.stem(token) for token in target_title]\n",
    "    \n",
    "    source_auth = source_info[3].split(\",\")\n",
    "    target_auth = target_info[3].split(\",\")\n",
    "    \n",
    "    overlap_title_test.append(len(set(source_title).intersection(set(target_title))))\n",
    "    temp_diff_test.append(int(source_info[1]) - int(target_info[1]))\n",
    "    comm_auth_test.append(len(set(source_auth).intersection(set(target_auth))))\n",
    "   \n",
    "    preds = nx.jaccard_coefficient(G_undirected, [(source, target)])\n",
    "    for _, _, p in preds:\n",
    "        jaccard_sim.append(p)\n",
    "        \n",
    "    counter += 1\n",
    "    if counter % 1000 == True:\n",
    "        print counter, \"testing examples processsed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert list of lists into array\n",
    "# documents as rows, unique words as columns (i.e., example as rows, features as columns)\n",
    "testing_features = np.array([overlap_title_test, temp_diff_test, comm_auth_test, jaccard_sim]).T\n",
    "\n",
    "# scale\n",
    "testing_features = preprocessing.scale(testing_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# write features to .csv file\n",
    "X_test = np.array(testing_set).T\n",
    "X_features_test = testing_features.T\n",
    "features_test = zip(X_test[0], X_test[1], X_features_test[0], X_features_test[1], X_features_test[2], X_features_test[3])\n",
    "with open(\"features_test.csv\",\"wb\") as feat:\n",
    "    csv_out = csv.writer(feat)\n",
    "    csv_out.writerow(('source', 'target', 'overlap_title', 'diff', 'common_author', 'jaccard_sim'))\n",
    "    for row in features_test:\n",
    "        csv_out.writerow(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the test data from features_test.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# reading test features\n",
    "with open(\"features_test.csv\", \"r\") as f:\n",
    "    reader = csv.reader(f)\n",
    "    feats_test = list(reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert labels into integers then into column array\n",
    "\n",
    "testing_features = [element[2:7] for element in feats_test[1:]]\n",
    "testing_features = np.array(testing_features, dtype=np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32648 [-0.56631167 -0.31764894 -0.23392443 -0.6281111 ]\n"
     ]
    }
   ],
   "source": [
    "print len(testing_features), testing_features[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the model for test data and write the link predictions in the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# issue predictions\n",
    "test_predictions_SVM = list(classifier.predict(testing_features))\n",
    "\n",
    "# write predictions to .csv file suitable for Kaggle (just make sure to add the column names)\n",
    "test_predictions_SVM = zip(range(len(testing_set)), test_predictions_SVM)\n",
    "\n",
    "with open(\"improved_predictions_jaccard.csv\",\"wb\") as pred1:\n",
    "    csv_out = csv.writer(pred1)\n",
    "    csv_out.writerow(('ID','category'))\n",
    "    for row in test_predictions_SVM:\n",
    "        csv_out.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
